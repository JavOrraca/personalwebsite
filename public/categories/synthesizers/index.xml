<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Synthesizers on Javier&#39;s Data Site</title>
    <link>/categories/synthesizers/</link>
    <description>Recent content in Synthesizers on Javier&#39;s Data Site</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 08 Oct 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/categories/synthesizers/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Machine Learning for Music Production</title>
      <link>/blog/2018-10-08-machine-learning-for-music-production/</link>
      <pubDate>Mon, 08 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/blog/2018-10-08-machine-learning-for-music-production/</guid>
      <description>If you know me personally, you likely know I enjoy playing with analog / digital synthesizers and experimental music production. I love seeing my interests cross&amp;hellip; FactorSynth, a new virtual musical tool and Ableton Live plug-in, uses machine learning to decompose your audio clips into elements. These musical elements can then be modified and recombined in various ways (in real-time). Check out this demo reel (my words don&amp;rsquo;t do this new device justice)!</description>
    </item>
    
  </channel>
</rss>