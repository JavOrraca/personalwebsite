<!DOCTYPE html>
<html>

<head>
    
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="chrome=1">
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="referrer" content="no-referrer">

<meta name="description" content="Javier Orraca&#39;s personal site for sharing analytics and data science resources through his blog and Scatter Podcast.">
<title>
    The Hitchhiker&rsquo;s Guide to Handle Big Data Using Spark - Javier Orraca. Data Scientist.
</title>


<link rel="shortcut icon" href="/sam.ico">








<link rel="stylesheet" href="/css/main.min.3c9fa6b3264a9f8be4f27730f1d5f0ded496304d03812ed49d97703ffb28122a.css" integrity="sha256-PJ&#43;msyZKn4vk8ncw8dXw3tSWME0DgS7UnZdwP/soEio=" crossorigin="anonymous" media="screen">





<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Didact+Gothic">

<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="/tn.png"/>

<meta name="twitter:title" content="The Hitchhiker&#39;s Guide to Handle Big Data Using Spark"/>
<meta name="twitter:description" content="Rahul Agarwal recently wrote an article for Towards Data Science that provides a great overview on the history of MapReduce, Spark, and using Python / PySpark for data engineering. I worked on a project recently with two people and we were shocked at how computationally efficient Spark was for our use case. We were able to load, read, manipulate, and explore over 30 GB of data in a Google Colab, GPU-enabled environment without reaching Google&rsquo;s RAM limitation&hellip; If you&rsquo;ve used Colab, you know that you can eat through 12 GB of GPU RAM quickly."/>

<meta property="og:title" content="The Hitchhiker&#39;s Guide to Handle Big Data Using Spark" />
<meta property="og:description" content="Rahul Agarwal recently wrote an article for Towards Data Science that provides a great overview on the history of MapReduce, Spark, and using Python / PySpark for data engineering. I worked on a project recently with two people and we were shocked at how computationally efficient Spark was for our use case. We were able to load, read, manipulate, and explore over 30 GB of data in a Google Colab, GPU-enabled environment without reaching Google&rsquo;s RAM limitation&hellip; If you&rsquo;ve used Colab, you know that you can eat through 12 GB of GPU RAM quickly." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/blog/2019-07-05-spark/" />
<meta property="og:image" content="/tn.png"/>
<meta property="article:published_time" content="2019-07-05T20:18:53-05:00" />
<meta property="article:modified_time" content="2019-07-05T20:18:53-05:00" /><meta property="og:site_name" content="Javier Orraca. Data Scientist." />


<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-127790709-3', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

    

    
    
    
    <title>
        
        The Hitchhiker&rsquo;s Guide to Handle Big Data Using Spark
        
    </title>
</head>

<body>
    
    
    <header class="wrap flex-container">
        <h1>The Hitchhiker&rsquo;s Guide to Handle Big Data Using Spark</h1>
    </header>
    
    <main class="wrap">
        
        <article role="article" class="flex-container"><p><img src="https://raw.githubusercontent.com/JavOrraca/Home/gh-pages/assets/img/PySpark.png" alt=""></p>
<p>Rahul Agarwal recently wrote an article for <em>Towards Data Science</em> that provides a great overview on the history of MapReduce, Spark, and using Python / PySpark for data engineering. I worked on a project recently with two people and we were shocked at how computationally efficient Spark was for our use case. We were able to load, read, manipulate, and explore over 30 GB of data in a Google Colab, GPU-enabled environment <em>without</em> reaching Google&rsquo;s RAM limitation&hellip; If you&rsquo;ve used Colab, you know that you can eat through 12 GB of GPU RAM <em>quickly</em>. I highly recommend this article for you if you&rsquo;re unfamiliar with Spark and PySpark for Python.</p>
<p>Source:</p>
<ul>
<li><a href="https://towardsdatascience.com/the-hitchhikers-guide-to-handle-big-data-using-spark">The Hitchhiker&rsquo;s Guide to Handle Big Data Using Spark</a></li>
</ul>
</article>
        

        
        
        <nav role="navigation" class="flex-container bottom-menu">
            
<hr />
<p>


    

    
        
            <a href="/blog">blog</a>
        
    
    
        
            &#183; 
            <a href="/scatterpodcast">scatter podcast</a>
        
            &#183; 
            <a href="/resources">resources</a>
        
            &#183; 
            <a href="/about">who is javier?</a>
        
    
    &#183; 
    <a href="/">
        main
    </a>

</p>
        </nav>
        
        
    </main>
    
    <footer class="flex-container footer">Javier Orraca. Data Scientist.</footer>
    
    
</body>

</html>