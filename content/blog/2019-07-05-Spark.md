---
date: "2019-07-05T20:18:53-05:00"
draft: false
showDate: true
tags:
- blog
title: The Hitchhiker's Guide to Handle Big Data Using Spark
---

![](https://raw.githubusercontent.com/JavOrraca/Home/gh-pages/assets/img/PySpark.png)

Rahul Agarwal recently wrote an article for _Towards Data Science_ that provides a great overview on the history of MapReduce, Spark, and using Python / PySpark for data engineering. I worked on a project recently with two people and we were shocked at how computationally efficient Spark was for our use case. We were able to load, read, manipulate, and explore over 30 GB of data in a Google Colab, GPU-enabled environment _without_ reaching Google's RAM limitation... If you've used Colab, you know that you can eat through 12 GB of GPU RAM _quickly_. I highly recommend this article for you if you're unfamiliar with Spark and PySpark for Python.

Source:
<br/>[The Hitchhiker's Guide to Handle Big Data Using Spark](https://towardsdatascience.com/the-hitchhikers-guide-to-handle-big-data-using-spark)